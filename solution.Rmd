# Install necessary libraries
install.packages(c("tidyverse","leaflet"))

# Importing the needed library
```{r}
library(tidyverse)
library(leaflet)
library(rgdal)
```

# import dataset
```{r}
data <- read_csv("annual_conc_by_monitor_2000.csv")
```
 
# print cols name in the data
spec(data) 

# Visualize the whole data table
View(data)

# After visualizing the data, we need to first filter the one we needed from the data because it contains all
# air pollution for United State in the year 2000.

# # Filter by state name, Select all data where the state name is South Carolina
SC  <- filter(data, `State Name` == "South Carolina")
view(SC)

# The next thing to do is data cleaning, to drop the columns that is not need in this Analysis
#  The data columns was study veey well in the data view, then we decided to create a new dataframe with the data
# will be need to create interpolation and spatial clusters

"""
The columns needed are
Latitude
Longitude
Parameter Name
Arithmetic Mean
"""
#  create a new dataframe with the needed columns
df <- SC[,c('Latitude', 'Longitude', 'Parameter Name','Arithmetic Mean')]
view the new dataframe
view(df)


# show the total count per parameters
view(df %>% count(`Parameter Name`))


# Filter out the Parameters needed in the Parameter Name column.


# The three parameters needed for this analysis are
# Nitrogen dioxide (NO2),
# Ozone (O3) and,
# PM2.5 - Local Conditions


# filter out the parametrs required
df1  <- filter(df, `Parameter Name` %in%  c("Nitrogen dioxide (NO2)", "Ozone", "PM2.5 - Local Conditions"))

# visualize the parameter  
view(df1)

# show the total count of each parameters
view(df1 %>% count(`Parameter Name`))


# Visualize the distribution of the Air pollution data using histogram
ggplot(data = df1) +   geom_bar(mapping = aes(x = `Parameter Name`))


# Check for duplicate locations
duplicated(df1)

# There must be only one lat/long per pollutant.
# to create a data with one lat/long per pollutant,we need only the distinct values of lat/log
# We will use the LAtitude, Longititude and Parameter Name as a single group to aggregate the Arithmetic Mean values
# into a single mean for each points

df2 = df1 %>% group_by(Latitude, Longitude,`Parameter Name`)%>%
  summarise(Average = mean(`Arithmetic Mean`),
  .groups = 'drop')


 view(df2)

# show the total count of each parameters
view(df2 %>% count(`Parameter Name`))


# Visualize the distribution of the Air pollution data using histogram
ggplot(data = df2) +   geom_bar(mapping = aes(x = `Parameter Name`))



# Display all the point on a map
```{r}
leaflet(data = df2)%>% 
  addTiles()%>%
  addMarkers()
```


## Interpolation
"
We are creating interpolation for each of the parameter
# Nitrogen dioxide (NO2),
# Ozone and,
# PM2.5 - Local Conditions

"

# Nitrogen Interpolation
Nitrogen  <- filter(df2, `Parameter Name` == "Nitrogen dioxide (NO2)")

# Display Nitrgoen points on a map
```{r}
leaflet(data = Nitrogen)%>% 
  addTiles()%>%
  addMarkers()
```
ggplot(Nitrogen, aes(x=as.factor(`Parameter Name`), y=Average)) + 
  geom_boxplot(fill="slateblue", alpha=0.2) + 
  xlab("Parameter Name")


# grab the long and lat from the data to cread a coords 

xy <- df2[,c(1,2)]

# Setting existing coordinate as lat-long system
Nitrogen_1 <- SpatialPointsDataFrame(coords = xy, data = df2,
                               proj4string = CRS("+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"))


# Transforming coordinate to UTM using EPSG=26916 for NAD83, UTM Zone=16N)
Nitrogen_pro <- spTransform(Nitrogen_1, CRS("+init=epsg:26916"))


# View the data property
Nitrogen_pro@proj4string


South_Carolina <- readOGR("https://raw.githubusercontent.com/unitedstates/districts/gh-pages/states/SC/shape.geojson")
South_Carolina@proj4string


# Transforming coordinate to UTM using EPSG=26916 for NAD83, UTM Zone=16N)
SC_pro <- spTransform(South_Carolina, CRS("+init=epsg:26916"))


# overlay Nitrogen on South Carolina boundary
plot(SC_pro, border = "red")
plot(Nitrogen_pro, add = TRUE)

#  IDW Interpolation

#  The gstat library contains a set of functions for Spatial and Spatio-Temporal Geostatistical Modelling, Prediction and Simulation. 

# Method Selection
# Initial parameter selection (e.g., k for IDW)
# Cross-Validate – Use LOOCV
# Prediction and map creation

# To create a grid around our study area, we will create a bounding box around it
extent.sc <- extent(SC_pro)
extent.sc

#Based on the extent of the boundary box we use the expand.grid() function to generate a data frame with x and y coordinates.

grid.south_carolina <- expand.grid(x = seq(from = round(extent.sc@xmin),
                                         to = round(extent.sc@xmax),
                                         by = 10000),
                                 y = seq(from = round(extent.sc@ymin),
                                         to = round(extent.sc@ymax),
                                         by = 10000))

head(grid.south_carolina , 10)


plot(grid.south_carolina)



# we cast it into a SpatialPoints object by applying the coordinates() function.

coordinates(grid.south_carolina) <- ~x + y
class(grid.south_carolina)

proj4string(grid.south_carolina) <- proj4string(Nitrogen_pro)
head(grid.south_carolina)

# Then we apply the gridded() function to cast the SpatialPoints to a SpatialPixels object.

gridded(grid.south_carolina) <- TRUE
class(grid.south_carolina)


# Finally we plot our regular grid of cell size 10 km, the administrative borders of the federal states within East Germany and the DWD weather stations.

plot(grid.south_carolina,
     main = paste("Weather Stations in East Germany\n and Interpolation Grid"),
     col = "grey",
     cex.main = 0.9)

plot(SC_pro, add = TRUE, border = "red")
plot(Nitrogen_pro, add = TRUE, pch = 15, cex = 0.5, col = "blue")


neighbors = length(Nitrogen_pro)
beta = 2

Nitrogen_idw = gstat(formula = Average ~ 1, # intercept only model
                 data = Nitrogen_pro, 
                 nmax = neighbors, 
                 set = list(idp = beta))



# Now that we have specified a gstat object we make use of the generic predict() function to interpolate our predictor variable for each pixel in our SpatialPixelsDataFrame object grid.east.germany.

south_carolina.No2 <- predict(object = Nitrogen_idw,
                                  newdata = grid.south_carolina)

plot(south_carolina.No2,
     main = "IDW Temperatur (°C)")
plot(SC_pro, add = TRUE, border = "white")
plot(Nitrogen_pro, add = TRUE, pch = 19, cex = 0.5, col = "green")



# In order to clip the SpatialPixelsDataFrame object grid.east.germany.temp, 
# we first create a RasterLayer object, using the raster()
# function, and then we apply the mask() function.

# masking
south_Carolina_No2 <- mask(raster(south_carolina.No2),SC_pro)



# plotting
main <- expression(paste("IDW Temperatur (°C), ", beta, " = 2"))
plot(south_Carolina_No2, main = main)
plot(SC_pro, add = TRUE, border = "white")
plot(Nitrogen_pro, add = TRUE, pch = 8, cex = 0.5, col = "red")




The output is an object of class sp, with the prediction results stored in the variable: var1.pred

```{r}
class(south_carolina.No2)
str(south_carolina.No2)
spplot(south_carolina.No2, "var1.pred")
```



## Cross Validation

The gstat package has a built in cross validation function for both IDW and Kriging, krige.cv()  

The krige.cv function can conduct both LOOCV and k-fold validation

- LOOCV, set nfold = number of observations


```{r}
LOOCV <- krige.cv(PM~1, 
                  pollution, 
                  nfold = nrow(pollution), # Set the number of folds to the number of rows
                  set = list(idp = 2)
)
```

View the stucture of the object.

```{r}
str(LOOCV)
```

View the LOOCV data

```{r}
LOOCV@data
```


Plot the residuals.

```{r}
spplot(LOOCV, "residual")
```



The $Y_i-\hat{Y_i}$ component is simply the values in the residual column . To calculate RMSE we will need to square our residuals, find the mean, and take the square.

```{r}
LOOCV@data$residual ^ 2 %>%
  mean() %>%
  sqrt()

```

This will need to be conducted a number of times. Here is a simple function to complete the same task.

```{r}
RMSE_resid <- function(x){
  return(sqrt(mean(x^2)))
} 
```

Try the function.

```{r}
RMSE_resid(LOOCV@data$residual)
```

At this point you could try different exponent values and compare the cross-validation to determine the optimal k.

```{r}
# Exponent of 1 (k)
LOOCV_k1 <- krige.cv(PM~1, 
                     pollution, 
                     nfold = nrow(pollution), # Set the number of folds to the number of rows
                     set = list(idp = 1)
)

# Exponent of 2 (k)
LOOCV_k2 <- krige.cv(PM~1, 
                     pollution, 
                     nfold = nrow(pollution), # Set the number of folds to the number of rows
                     set = list(idp = 2)
)

# Exponent of 3 (k)
LOOCV_k3 <- krige.cv(PM~1, 
                     pollution, 
                     nfold = nrow(pollution), # Set the number of folds to the number of rows
                     set = list(idp = 3)
)



```

Determine the best value of k, using RMSE of the residuals.
```{r}
# Determine RMSE when k = 1
RMSE_resid(LOOCV_k1@data$residual)

# Determine RMSE when k = 2
RMSE_resid(LOOCV_k2@data$residual)

# Determine RMSE when k = 3
RMSE_resid(LOOCV_k3@data$residual)















#  Ozone Interpolation
Ozone <- filter(df2, `Parameter Name` == "Ozone")

# Display ozone points on a map
```{r}
leaflet(data = Ozone)%>% 
  addTiles()%>%
  addMarkers()
```











# Ozone Interpolation

PM <- filter(df2, `Parameter Name` == "PM2.5 - Local Conditions")

# Display ozone points on a map
```{r}
leaflet(data = PM)%>% 
  addTiles()%>%
  addMarkers()
```








# Export the cleaned dataframe to be used for kringing
write.csv(df2,"South_Californaia.csv", row.names = FALSE)